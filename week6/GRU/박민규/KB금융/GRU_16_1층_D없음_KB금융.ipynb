{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GRU_16_1층_D없음_KB금융.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"dqUXm1U68Slp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657975510480,"user_tz":-540,"elapsed":82379,"user":{"displayName":"박민규","userId":"00586156377257418934"}},"outputId":"ba6567b1-e30f-41f8-ce24-3922dbafbb4e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0sQZP-mN8EEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657975983057,"user_tz":-540,"elapsed":472583,"user":{"displayName":"박민규","userId":"00586156377257418934"}},"outputId":"023c01e4-9019-4285-c953-7be003cea493"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ta\n","  Downloading ta-0.10.1.tar.gz (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ta) (1.15.0)\n","Building wheels for collected packages: ta\n","  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ta: filename=ta-0.10.1-py3-none-any.whl size=28985 sha256=05b8e7bc07e84089787be4953f4e76ed7a3dff6775d7485527f1a73815996c47\n","  Stored in directory: /root/.cache/pip/wheels/bc/2a/c2/a56e77d07edc16a1fa7fb012667e55cb0643cfa65996bddecc\n","Successfully built ta\n","Installing collected packages: ta\n","Successfully installed ta-0.10.1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ta/trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n","  dip[idx] = 100 * (self._dip[idx] / value)\n","/usr/local/lib/python3.7/dist-packages/ta/trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n","  din[idx] = 100 * (self._din[idx] / value)\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/100\n","32/34 [===========================>..] - ETA: 0s - loss: 0.0876\n","Epoch 1: val_loss improved from inf to 0.00373, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 4s 29ms/step - loss: 0.0829 - val_loss: 0.0037\n","Epoch 2/100\n","33/34 [============================>.] - ETA: 0s - loss: 0.0043\n","Epoch 2: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 18ms/step - loss: 0.0042 - val_loss: 0.0065\n","Epoch 3/100\n","33/34 [============================>.] - ETA: 0s - loss: 0.0024\n","Epoch 3: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 17ms/step - loss: 0.0024 - val_loss: 0.0069\n","Epoch 4/100\n","32/34 [===========================>..] - ETA: 0s - loss: 0.0020\n","Epoch 4: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 17ms/step - loss: 0.0020 - val_loss: 0.0049\n","Epoch 5/100\n","32/34 [===========================>..] - ETA: 0s - loss: 0.0017\n","Epoch 5: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 17ms/step - loss: 0.0017 - val_loss: 0.0050\n","Epoch 6/100\n","32/34 [===========================>..] - ETA: 0s - loss: 0.0015\n","Epoch 6: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 17ms/step - loss: 0.0015 - val_loss: 0.0052\n","Epoch 7/100\n","33/34 [============================>.] - ETA: 0s - loss: 0.0013\n","Epoch 7: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 17ms/step - loss: 0.0013 - val_loss: 0.0063\n","Epoch 8/100\n","34/34 [==============================] - ETA: 0s - loss: 0.0013\n","Epoch 8: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 0.0061\n","Epoch 9/100\n","32/34 [===========================>..] - ETA: 0s - loss: 0.0011\n","Epoch 9: val_loss did not improve from 0.00373\n","34/34 [==============================] - 1s 17ms/step - loss: 0.0011 - val_loss: 0.0044\n","Epoch 10/100\n","32/34 [===========================>..] - ETA: 0s - loss: 9.3277e-04\n","Epoch 10: val_loss improved from 0.00373 to 0.00321, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 17ms/step - loss: 9.3510e-04 - val_loss: 0.0032\n","Epoch 11/100\n","32/34 [===========================>..] - ETA: 0s - loss: 9.0077e-04\n","Epoch 11: val_loss improved from 0.00321 to 0.00217, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 17ms/step - loss: 8.9835e-04 - val_loss: 0.0022\n","Epoch 12/100\n","34/34 [==============================] - ETA: 0s - loss: 8.1606e-04\n","Epoch 12: val_loss did not improve from 0.00217\n","34/34 [==============================] - 1s 18ms/step - loss: 8.1606e-04 - val_loss: 0.0036\n","Epoch 13/100\n","32/34 [===========================>..] - ETA: 0s - loss: 8.0355e-04\n","Epoch 13: val_loss did not improve from 0.00217\n","34/34 [==============================] - 1s 18ms/step - loss: 8.1422e-04 - val_loss: 0.0023\n","Epoch 14/100\n","34/34 [==============================] - ETA: 0s - loss: 7.6074e-04\n","Epoch 14: val_loss did not improve from 0.00217\n","34/34 [==============================] - 1s 17ms/step - loss: 7.6074e-04 - val_loss: 0.0022\n","Epoch 15/100\n","32/34 [===========================>..] - ETA: 0s - loss: 7.0113e-04\n","Epoch 15: val_loss did not improve from 0.00217\n","34/34 [==============================] - 1s 18ms/step - loss: 7.0705e-04 - val_loss: 0.0023\n","Epoch 16/100\n","32/34 [===========================>..] - ETA: 0s - loss: 6.8966e-04\n","Epoch 16: val_loss improved from 0.00217 to 0.00186, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 18ms/step - loss: 7.1355e-04 - val_loss: 0.0019\n","Epoch 17/100\n","31/34 [==========================>...] - ETA: 0s - loss: 6.6565e-04\n","Epoch 17: val_loss improved from 0.00186 to 0.00177, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 18ms/step - loss: 6.5745e-04 - val_loss: 0.0018\n","Epoch 18/100\n","32/34 [===========================>..] - ETA: 0s - loss: 6.4007e-04\n","Epoch 18: val_loss did not improve from 0.00177\n","34/34 [==============================] - 1s 17ms/step - loss: 6.3240e-04 - val_loss: 0.0021\n","Epoch 19/100\n","32/34 [===========================>..] - ETA: 0s - loss: 6.1063e-04\n","Epoch 19: val_loss did not improve from 0.00177\n","34/34 [==============================] - 1s 17ms/step - loss: 6.1592e-04 - val_loss: 0.0020\n","Epoch 20/100\n","32/34 [===========================>..] - ETA: 0s - loss: 6.1616e-04\n","Epoch 20: val_loss did not improve from 0.00177\n","34/34 [==============================] - 1s 17ms/step - loss: 6.1192e-04 - val_loss: 0.0021\n","Epoch 21/100\n","33/34 [============================>.] - ETA: 0s - loss: 5.7450e-04\n","Epoch 21: val_loss did not improve from 0.00177\n","34/34 [==============================] - 1s 18ms/step - loss: 5.8021e-04 - val_loss: 0.0020\n","Epoch 22/100\n","33/34 [============================>.] - ETA: 0s - loss: 5.7412e-04\n","Epoch 22: val_loss did not improve from 0.00177\n","34/34 [==============================] - 1s 17ms/step - loss: 5.7100e-04 - val_loss: 0.0024\n","Epoch 23/100\n","33/34 [============================>.] - ETA: 0s - loss: 5.5404e-04\n","Epoch 23: val_loss did not improve from 0.00177\n","34/34 [==============================] - 1s 17ms/step - loss: 5.4776e-04 - val_loss: 0.0019\n","Epoch 24/100\n","34/34 [==============================] - ETA: 0s - loss: 5.3451e-04\n","Epoch 24: val_loss improved from 0.00177 to 0.00151, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 19ms/step - loss: 5.3451e-04 - val_loss: 0.0015\n","Epoch 25/100\n","32/34 [===========================>..] - ETA: 0s - loss: 5.5526e-04\n","Epoch 25: val_loss did not improve from 0.00151\n","34/34 [==============================] - 1s 18ms/step - loss: 5.5314e-04 - val_loss: 0.0017\n","Epoch 26/100\n","33/34 [============================>.] - ETA: 0s - loss: 5.8722e-04\n","Epoch 26: val_loss did not improve from 0.00151\n","34/34 [==============================] - 1s 18ms/step - loss: 5.8325e-04 - val_loss: 0.0023\n","Epoch 27/100\n","32/34 [===========================>..] - ETA: 0s - loss: 5.4538e-04\n","Epoch 27: val_loss did not improve from 0.00151\n","34/34 [==============================] - 1s 17ms/step - loss: 5.3974e-04 - val_loss: 0.0026\n","Epoch 28/100\n","33/34 [============================>.] - ETA: 0s - loss: 5.1906e-04\n","Epoch 28: val_loss did not improve from 0.00151\n","34/34 [==============================] - 1s 19ms/step - loss: 5.2574e-04 - val_loss: 0.0017\n","Epoch 29/100\n","33/34 [============================>.] - ETA: 0s - loss: 5.1761e-04\n","Epoch 29: val_loss did not improve from 0.00151\n","34/34 [==============================] - 1s 17ms/step - loss: 5.1024e-04 - val_loss: 0.0016\n","Epoch 30/100\n","34/34 [==============================] - ETA: 0s - loss: 5.0194e-04\n","Epoch 30: val_loss improved from 0.00151 to 0.00134, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 19ms/step - loss: 5.0194e-04 - val_loss: 0.0013\n","Epoch 31/100\n","34/34 [==============================] - ETA: 0s - loss: 4.7717e-04\n","Epoch 31: val_loss did not improve from 0.00134\n","34/34 [==============================] - 1s 20ms/step - loss: 4.7717e-04 - val_loss: 0.0017\n","Epoch 32/100\n","31/34 [==========================>...] - ETA: 0s - loss: 5.3328e-04\n","Epoch 32: val_loss improved from 0.00134 to 0.00109, saving model to model/tmp_checkpoint.h5\n","34/34 [==============================] - 1s 20ms/step - loss: 5.5223e-04 - val_loss: 0.0011\n","Epoch 33/100\n","34/34 [==============================] - ETA: 0s - loss: 5.7325e-04\n","Epoch 33: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 20ms/step - loss: 5.7325e-04 - val_loss: 0.0021\n","Epoch 34/100\n","34/34 [==============================] - ETA: 0s - loss: 4.8283e-04\n","Epoch 34: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 19ms/step - loss: 4.8283e-04 - val_loss: 0.0018\n","Epoch 35/100\n","32/34 [===========================>..] - ETA: 0s - loss: 5.2223e-04\n","Epoch 35: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 21ms/step - loss: 5.1847e-04 - val_loss: 0.0025\n","Epoch 36/100\n","32/34 [===========================>..] - ETA: 0s - loss: 4.7174e-04\n","Epoch 36: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 20ms/step - loss: 4.6432e-04 - val_loss: 0.0017\n","Epoch 37/100\n","32/34 [===========================>..] - ETA: 0s - loss: 5.4042e-04\n","Epoch 37: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 21ms/step - loss: 5.8897e-04 - val_loss: 0.0029\n","Epoch 38/100\n","31/34 [==========================>...] - ETA: 0s - loss: 5.1206e-04\n","Epoch 38: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 29ms/step - loss: 5.0339e-04 - val_loss: 0.0017\n","Epoch 39/100\n","32/34 [===========================>..] - ETA: 0s - loss: 5.5431e-04\n","Epoch 39: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 31ms/step - loss: 5.3885e-04 - val_loss: 0.0036\n","Epoch 40/100\n","34/34 [==============================] - ETA: 0s - loss: 5.3792e-04\n","Epoch 40: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 29ms/step - loss: 5.3792e-04 - val_loss: 0.0022\n","Epoch 41/100\n","32/34 [===========================>..] - ETA: 0s - loss: 4.2707e-04\n","Epoch 41: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 17ms/step - loss: 4.3937e-04 - val_loss: 0.0014\n","Epoch 42/100\n","34/34 [==============================] - ETA: 0s - loss: 4.5029e-04\n","Epoch 42: val_loss did not improve from 0.00109\n","34/34 [==============================] - 1s 18ms/step - loss: 4.5029e-04 - val_loss: 0.0012\n","1000길이의 데이터 적용 완료\n"," 길이: 1000, RMSE:2834.579947819444\n","[2834.579947819444]\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0396\n","Epoch 1: val_loss improved from inf to 0.01262, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 2s 20ms/step - loss: 0.0396 - val_loss: 0.0126\n","Epoch 2/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0036\n","Epoch 2: val_loss improved from 0.01262 to 0.00591, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 0.0036 - val_loss: 0.0059\n","Epoch 3/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0021\n","Epoch 3: val_loss improved from 0.00591 to 0.00438, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 21ms/step - loss: 0.0021 - val_loss: 0.0044\n","Epoch 4/100\n","69/69 [==============================] - ETA: 0s - loss: 0.0014\n","Epoch 4: val_loss improved from 0.00438 to 0.00391, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 21ms/step - loss: 0.0014 - val_loss: 0.0039\n","Epoch 5/100\n","67/69 [============================>.] - ETA: 0s - loss: 0.0011\n","Epoch 5: val_loss improved from 0.00391 to 0.00242, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 0.0011 - val_loss: 0.0024\n","Epoch 6/100\n","68/69 [============================>.] - ETA: 0s - loss: 8.2745e-04\n","Epoch 6: val_loss improved from 0.00242 to 0.00137, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 8.2122e-04 - val_loss: 0.0014\n","Epoch 7/100\n","67/69 [============================>.] - ETA: 0s - loss: 7.8696e-04\n","Epoch 7: val_loss did not improve from 0.00137\n","69/69 [==============================] - 1s 17ms/step - loss: 7.8052e-04 - val_loss: 0.0015\n","Epoch 8/100\n","69/69 [==============================] - ETA: 0s - loss: 6.4367e-04\n","Epoch 8: val_loss improved from 0.00137 to 0.00073, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 6.4367e-04 - val_loss: 7.2925e-04\n","Epoch 9/100\n","66/69 [===========================>..] - ETA: 0s - loss: 6.0555e-04\n","Epoch 9: val_loss improved from 0.00073 to 0.00068, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 6.1170e-04 - val_loss: 6.7556e-04\n","Epoch 10/100\n","68/69 [============================>.] - ETA: 0s - loss: 5.5737e-04\n","Epoch 10: val_loss did not improve from 0.00068\n","69/69 [==============================] - 1s 18ms/step - loss: 5.5336e-04 - val_loss: 9.5016e-04\n","Epoch 11/100\n","67/69 [============================>.] - ETA: 0s - loss: 5.3646e-04\n","Epoch 11: val_loss improved from 0.00068 to 0.00053, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 5.2951e-04 - val_loss: 5.3192e-04\n","Epoch 12/100\n","69/69 [==============================] - ETA: 0s - loss: 5.2906e-04\n","Epoch 12: val_loss did not improve from 0.00053\n","69/69 [==============================] - 1s 17ms/step - loss: 5.2906e-04 - val_loss: 6.2982e-04\n","Epoch 13/100\n","66/69 [===========================>..] - ETA: 0s - loss: 5.2625e-04\n","Epoch 13: val_loss did not improve from 0.00053\n","69/69 [==============================] - 1s 17ms/step - loss: 5.2775e-04 - val_loss: 7.2940e-04\n","Epoch 14/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.8330e-04\n","Epoch 14: val_loss did not improve from 0.00053\n","69/69 [==============================] - 1s 16ms/step - loss: 4.8861e-04 - val_loss: 0.0014\n","Epoch 15/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.8592e-04\n","Epoch 15: val_loss did not improve from 0.00053\n","69/69 [==============================] - 1s 17ms/step - loss: 4.8712e-04 - val_loss: 7.2659e-04\n","Epoch 16/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.6814e-04\n","Epoch 16: val_loss improved from 0.00053 to 0.00049, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 4.6723e-04 - val_loss: 4.8864e-04\n","Epoch 17/100\n","69/69 [==============================] - ETA: 0s - loss: 4.9255e-04\n","Epoch 17: val_loss did not improve from 0.00049\n","69/69 [==============================] - 1s 18ms/step - loss: 4.9255e-04 - val_loss: 6.8051e-04\n","Epoch 18/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.8218e-04\n","Epoch 18: val_loss improved from 0.00049 to 0.00043, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 4.7883e-04 - val_loss: 4.3040e-04\n","Epoch 19/100\n","69/69 [==============================] - ETA: 0s - loss: 4.5435e-04\n","Epoch 19: val_loss did not improve from 0.00043\n","69/69 [==============================] - 1s 17ms/step - loss: 4.5435e-04 - val_loss: 7.9711e-04\n","Epoch 20/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.9480e-04\n","Epoch 20: val_loss improved from 0.00043 to 0.00041, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 4.9417e-04 - val_loss: 4.1336e-04\n","Epoch 21/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.5597e-04\n","Epoch 21: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 16ms/step - loss: 4.6284e-04 - val_loss: 0.0011\n","Epoch 22/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.6349e-04\n","Epoch 22: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 17ms/step - loss: 4.6698e-04 - val_loss: 7.8855e-04\n","Epoch 23/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.6789e-04\n","Epoch 23: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 17ms/step - loss: 4.6410e-04 - val_loss: 5.8269e-04\n","Epoch 24/100\n","69/69 [==============================] - ETA: 0s - loss: 4.4936e-04\n","Epoch 24: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.4936e-04 - val_loss: 4.5184e-04\n","Epoch 25/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.8385e-04\n","Epoch 25: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.8058e-04 - val_loss: 4.4414e-04\n","Epoch 26/100\n","69/69 [==============================] - ETA: 0s - loss: 4.4556e-04\n","Epoch 26: val_loss improved from 0.00041 to 0.00041, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 18ms/step - loss: 4.4556e-04 - val_loss: 4.0830e-04\n","Epoch 27/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.6753e-04\n","Epoch 27: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.6493e-04 - val_loss: 4.4028e-04\n","Epoch 28/100\n","68/69 [============================>.] - ETA: 0s - loss: 4.0799e-04\n","Epoch 28: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 17ms/step - loss: 4.0713e-04 - val_loss: 4.4699e-04\n","Epoch 29/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.0925e-04\n","Epoch 29: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.1088e-04 - val_loss: 4.5625e-04\n","Epoch 30/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.4425e-04\n","Epoch 30: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.4435e-04 - val_loss: 4.4777e-04\n","Epoch 31/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.2507e-04\n","Epoch 31: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 19ms/step - loss: 4.2289e-04 - val_loss: 6.4998e-04\n","Epoch 32/100\n","68/69 [============================>.] - ETA: 0s - loss: 4.1497e-04\n","Epoch 32: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.2024e-04 - val_loss: 6.5610e-04\n","Epoch 33/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.1538e-04\n","Epoch 33: val_loss did not improve from 0.00041\n","69/69 [==============================] - 1s 18ms/step - loss: 4.1704e-04 - val_loss: 4.3725e-04\n","Epoch 34/100\n","68/69 [============================>.] - ETA: 0s - loss: 3.9260e-04\n","Epoch 34: val_loss improved from 0.00041 to 0.00038, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 3.9110e-04 - val_loss: 3.8278e-04\n","Epoch 35/100\n","68/69 [============================>.] - ETA: 0s - loss: 4.5165e-04\n","Epoch 35: val_loss improved from 0.00038 to 0.00036, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 4.4673e-04 - val_loss: 3.6229e-04\n","Epoch 36/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.0918e-04\n","Epoch 36: val_loss did not improve from 0.00036\n","69/69 [==============================] - 1s 17ms/step - loss: 4.0825e-04 - val_loss: 3.8372e-04\n","Epoch 37/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.2735e-04\n","Epoch 37: val_loss did not improve from 0.00036\n","69/69 [==============================] - 1s 17ms/step - loss: 4.2150e-04 - val_loss: 4.6959e-04\n","Epoch 38/100\n","67/69 [============================>.] - ETA: 0s - loss: 3.8921e-04\n","Epoch 38: val_loss did not improve from 0.00036\n","69/69 [==============================] - 1s 17ms/step - loss: 3.9229e-04 - val_loss: 5.8296e-04\n","Epoch 39/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.1999e-04\n","Epoch 39: val_loss did not improve from 0.00036\n","69/69 [==============================] - 1s 17ms/step - loss: 4.2105e-04 - val_loss: 3.7449e-04\n","Epoch 40/100\n","66/69 [===========================>..] - ETA: 0s - loss: 3.8958e-04\n","Epoch 40: val_loss did not improve from 0.00036\n","69/69 [==============================] - 1s 17ms/step - loss: 3.8889e-04 - val_loss: 3.6503e-04\n","Epoch 41/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.2540e-04\n","Epoch 41: val_loss improved from 0.00036 to 0.00036, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 4.1896e-04 - val_loss: 3.5843e-04\n","Epoch 42/100\n","66/69 [===========================>..] - ETA: 0s - loss: 3.9328e-04\n","Epoch 42: val_loss improved from 0.00036 to 0.00035, saving model to model/tmp_checkpoint.h5\n","69/69 [==============================] - 1s 17ms/step - loss: 3.9875e-04 - val_loss: 3.4988e-04\n","Epoch 43/100\n","67/69 [============================>.] - ETA: 0s - loss: 4.3843e-04\n","Epoch 43: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 4.3133e-04 - val_loss: 3.5094e-04\n","Epoch 44/100\n","69/69 [==============================] - ETA: 0s - loss: 3.8391e-04\n","Epoch 44: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 3.8391e-04 - val_loss: 3.5645e-04\n","Epoch 45/100\n","68/69 [============================>.] - ETA: 0s - loss: 4.5112e-04\n","Epoch 45: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 4.5336e-04 - val_loss: 3.6048e-04\n","Epoch 46/100\n","68/69 [============================>.] - ETA: 0s - loss: 4.1224e-04\n","Epoch 46: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 4.1222e-04 - val_loss: 3.6897e-04\n","Epoch 47/100\n","67/69 [============================>.] - ETA: 0s - loss: 3.9999e-04\n","Epoch 47: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 16ms/step - loss: 3.9619e-04 - val_loss: 4.2904e-04\n","Epoch 48/100\n","68/69 [============================>.] - ETA: 0s - loss: 3.6986e-04\n","Epoch 48: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 3.7350e-04 - val_loss: 4.3950e-04\n","Epoch 49/100\n","66/69 [===========================>..] - ETA: 0s - loss: 4.3139e-04\n","Epoch 49: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 4.3250e-04 - val_loss: 3.9247e-04\n","Epoch 50/100\n","67/69 [============================>.] - ETA: 0s - loss: 3.6308e-04\n","Epoch 50: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 18ms/step - loss: 3.6620e-04 - val_loss: 4.4890e-04\n","Epoch 51/100\n","68/69 [============================>.] - ETA: 0s - loss: 3.9509e-04\n","Epoch 51: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 17ms/step - loss: 3.9542e-04 - val_loss: 3.9205e-04\n","Epoch 52/100\n","69/69 [==============================] - ETA: 0s - loss: 5.0709e-04\n","Epoch 52: val_loss did not improve from 0.00035\n","69/69 [==============================] - 1s 18ms/step - loss: 5.0709e-04 - val_loss: 5.8791e-04\n","2000길이의 데이터 적용 완료\n"," 길이: 2000, RMSE:1356.3687319050114\n","[2834.579947819444, 1356.3687319050114]\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/100\n","104/104 [==============================] - ETA: 0s - loss: 0.0048\n","Epoch 1: val_loss improved from inf to 0.00384, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 3s 19ms/step - loss: 0.0048 - val_loss: 0.0038\n","Epoch 2/100\n","102/104 [============================>.] - ETA: 0s - loss: 0.0012\n","Epoch 2: val_loss did not improve from 0.00384\n","104/104 [==============================] - 2s 17ms/step - loss: 0.0012 - val_loss: 0.0057\n","Epoch 3/100\n","102/104 [============================>.] - ETA: 0s - loss: 9.1195e-04\n","Epoch 3: val_loss improved from 0.00384 to 0.00106, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 17ms/step - loss: 9.0532e-04 - val_loss: 0.0011\n","Epoch 4/100\n","103/104 [============================>.] - ETA: 0s - loss: 6.4115e-04\n","Epoch 4: val_loss did not improve from 0.00106\n","104/104 [==============================] - 2s 16ms/step - loss: 6.4220e-04 - val_loss: 0.0013\n","Epoch 5/100\n","102/104 [============================>.] - ETA: 0s - loss: 5.8619e-04\n","Epoch 5: val_loss improved from 0.00106 to 0.00089, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 17ms/step - loss: 5.9697e-04 - val_loss: 8.8624e-04\n","Epoch 6/100\n","102/104 [============================>.] - ETA: 0s - loss: 6.1054e-04\n","Epoch 6: val_loss did not improve from 0.00089\n","104/104 [==============================] - 2s 17ms/step - loss: 6.0646e-04 - val_loss: 0.0011\n","Epoch 7/100\n","102/104 [============================>.] - ETA: 0s - loss: 5.6428e-04\n","Epoch 7: val_loss improved from 0.00089 to 0.00071, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 19ms/step - loss: 5.6353e-04 - val_loss: 7.1190e-04\n","Epoch 8/100\n","102/104 [============================>.] - ETA: 0s - loss: 5.7576e-04\n","Epoch 8: val_loss improved from 0.00071 to 0.00070, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 23ms/step - loss: 5.7147e-04 - val_loss: 6.9693e-04\n","Epoch 9/100\n","104/104 [==============================] - ETA: 0s - loss: 4.8527e-04\n","Epoch 9: val_loss did not improve from 0.00070\n","104/104 [==============================] - 2s 19ms/step - loss: 4.8527e-04 - val_loss: 7.2036e-04\n","Epoch 10/100\n","103/104 [============================>.] - ETA: 0s - loss: 5.0040e-04\n","Epoch 10: val_loss improved from 0.00070 to 0.00068, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 18ms/step - loss: 4.9958e-04 - val_loss: 6.8143e-04\n","Epoch 11/100\n","101/104 [============================>.] - ETA: 0s - loss: 5.0037e-04\n","Epoch 11: val_loss did not improve from 0.00068\n","104/104 [==============================] - 2s 18ms/step - loss: 4.9412e-04 - val_loss: 9.1139e-04\n","Epoch 12/100\n","102/104 [============================>.] - ETA: 0s - loss: 4.5306e-04\n","Epoch 12: val_loss did not improve from 0.00068\n","104/104 [==============================] - 2s 17ms/step - loss: 4.5417e-04 - val_loss: 8.5265e-04\n","Epoch 13/100\n","102/104 [============================>.] - ETA: 0s - loss: 4.5020e-04\n","Epoch 13: val_loss did not improve from 0.00068\n","104/104 [==============================] - 2s 17ms/step - loss: 4.4849e-04 - val_loss: 0.0011\n","Epoch 14/100\n","104/104 [==============================] - ETA: 0s - loss: 4.5906e-04\n","Epoch 14: val_loss did not improve from 0.00068\n","104/104 [==============================] - 2s 17ms/step - loss: 4.5906e-04 - val_loss: 0.0010\n","Epoch 15/100\n","101/104 [============================>.] - ETA: 0s - loss: 4.1173e-04\n","Epoch 15: val_loss improved from 0.00068 to 0.00067, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 17ms/step - loss: 4.1456e-04 - val_loss: 6.6578e-04\n","Epoch 16/100\n","102/104 [============================>.] - ETA: 0s - loss: 4.5788e-04\n","Epoch 16: val_loss did not improve from 0.00067\n","104/104 [==============================] - 2s 17ms/step - loss: 4.5472e-04 - val_loss: 7.2174e-04\n","Epoch 17/100\n","104/104 [==============================] - ETA: 0s - loss: 3.9116e-04\n","Epoch 17: val_loss improved from 0.00067 to 0.00063, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 17ms/step - loss: 3.9116e-04 - val_loss: 6.3362e-04\n","Epoch 18/100\n","103/104 [============================>.] - ETA: 0s - loss: 4.8508e-04\n","Epoch 18: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 4.8500e-04 - val_loss: 9.0945e-04\n","Epoch 19/100\n","103/104 [============================>.] - ETA: 0s - loss: 3.8822e-04\n","Epoch 19: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 3.8699e-04 - val_loss: 0.0016\n","Epoch 20/100\n","104/104 [==============================] - ETA: 0s - loss: 4.1313e-04\n","Epoch 20: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 17ms/step - loss: 4.1313e-04 - val_loss: 6.7297e-04\n","Epoch 21/100\n","103/104 [============================>.] - ETA: 0s - loss: 4.9872e-04\n","Epoch 21: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 4.9608e-04 - val_loss: 7.1082e-04\n","Epoch 22/100\n","101/104 [============================>.] - ETA: 0s - loss: 3.5563e-04\n","Epoch 22: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 17ms/step - loss: 3.6022e-04 - val_loss: 0.0012\n","Epoch 23/100\n","103/104 [============================>.] - ETA: 0s - loss: 4.2344e-04\n","Epoch 23: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 4.2186e-04 - val_loss: 0.0014\n","Epoch 24/100\n","104/104 [==============================] - ETA: 0s - loss: 4.2632e-04\n","Epoch 24: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 17ms/step - loss: 4.2632e-04 - val_loss: 8.2204e-04\n","Epoch 25/100\n","103/104 [============================>.] - ETA: 0s - loss: 3.9967e-04\n","Epoch 25: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 3.9869e-04 - val_loss: 0.0012\n","Epoch 26/100\n","102/104 [============================>.] - ETA: 0s - loss: 4.3793e-04\n","Epoch 26: val_loss improved from 0.00063 to 0.00063, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 17ms/step - loss: 4.3846e-04 - val_loss: 6.2933e-04\n","Epoch 27/100\n","103/104 [============================>.] - ETA: 0s - loss: 4.0589e-04\n","Epoch 27: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 4.0470e-04 - val_loss: 8.3821e-04\n","Epoch 28/100\n","104/104 [==============================] - ETA: 0s - loss: 3.6108e-04\n","Epoch 28: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 3.6108e-04 - val_loss: 8.5058e-04\n","Epoch 29/100\n","103/104 [============================>.] - ETA: 0s - loss: 4.6192e-04\n","Epoch 29: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 17ms/step - loss: 4.6420e-04 - val_loss: 0.0018\n","Epoch 30/100\n","103/104 [============================>.] - ETA: 0s - loss: 4.4165e-04\n","Epoch 30: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 4.4127e-04 - val_loss: 0.0026\n","Epoch 31/100\n","101/104 [============================>.] - ETA: 0s - loss: 3.7080e-04\n","Epoch 31: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 3.8021e-04 - val_loss: 6.3925e-04\n","Epoch 32/100\n","104/104 [==============================] - ETA: 0s - loss: 3.7615e-04\n","Epoch 32: val_loss did not improve from 0.00063\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7615e-04 - val_loss: 6.3030e-04\n","Epoch 33/100\n","102/104 [============================>.] - ETA: 0s - loss: 4.0065e-04\n","Epoch 33: val_loss improved from 0.00063 to 0.00061, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 16ms/step - loss: 4.0284e-04 - val_loss: 6.0618e-04\n","Epoch 34/100\n","101/104 [============================>.] - ETA: 0s - loss: 3.6728e-04\n","Epoch 34: val_loss did not improve from 0.00061\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7001e-04 - val_loss: 0.0017\n","Epoch 35/100\n","101/104 [============================>.] - ETA: 0s - loss: 4.1855e-04\n","Epoch 35: val_loss improved from 0.00061 to 0.00059, saving model to model/tmp_checkpoint.h5\n","104/104 [==============================] - 2s 16ms/step - loss: 4.1846e-04 - val_loss: 5.9029e-04\n","Epoch 36/100\n","104/104 [==============================] - ETA: 0s - loss: 3.7524e-04\n","Epoch 36: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7524e-04 - val_loss: 0.0015\n","Epoch 37/100\n","102/104 [============================>.] - ETA: 0s - loss: 3.5131e-04\n","Epoch 37: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.4986e-04 - val_loss: 8.2975e-04\n","Epoch 38/100\n","103/104 [============================>.] - ETA: 0s - loss: 3.4430e-04\n","Epoch 38: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.4322e-04 - val_loss: 8.9766e-04\n","Epoch 39/100\n","102/104 [============================>.] - ETA: 0s - loss: 3.7359e-04\n","Epoch 39: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7145e-04 - val_loss: 0.0020\n","Epoch 40/100\n","102/104 [============================>.] - ETA: 0s - loss: 3.5021e-04\n","Epoch 40: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.4700e-04 - val_loss: 0.0014\n","Epoch 41/100\n","102/104 [============================>.] - ETA: 0s - loss: 3.7791e-04\n","Epoch 41: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7668e-04 - val_loss: 0.0010\n","Epoch 42/100\n","104/104 [==============================] - ETA: 0s - loss: 3.7235e-04\n","Epoch 42: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7235e-04 - val_loss: 0.0015\n","Epoch 43/100\n","101/104 [============================>.] - ETA: 0s - loss: 3.7965e-04\n","Epoch 43: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.7635e-04 - val_loss: 0.0012\n","Epoch 44/100\n","103/104 [============================>.] - ETA: 0s - loss: 3.9532e-04\n","Epoch 44: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.9501e-04 - val_loss: 0.0012\n","Epoch 45/100\n","104/104 [==============================] - ETA: 0s - loss: 3.6860e-04\n","Epoch 45: val_loss did not improve from 0.00059\n","104/104 [==============================] - 2s 16ms/step - loss: 3.6860e-04 - val_loss: 0.0012\n","3000길이의 데이터 적용 완료\n"," 길이: 3000, RMSE:1277.7690059375616\n","[2834.579947819444, 1356.3687319050114, 1277.7690059375616]\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/100\n","113/113 [==============================] - ETA: 0s - loss: 0.0290\n","Epoch 1: val_loss improved from inf to 0.00367, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 6s 46ms/step - loss: 0.0290 - val_loss: 0.0037\n","Epoch 2/100\n","113/113 [==============================] - ETA: 0s - loss: 0.0024\n","Epoch 2: val_loss did not improve from 0.00367\n","113/113 [==============================] - 5s 44ms/step - loss: 0.0024 - val_loss: 0.0066\n","Epoch 3/100\n","112/113 [============================>.] - ETA: 0s - loss: 0.0015\n","Epoch 3: val_loss did not improve from 0.00367\n","113/113 [==============================] - 5s 43ms/step - loss: 0.0015 - val_loss: 0.0105\n","Epoch 4/100\n","113/113 [==============================] - ETA: 0s - loss: 0.0012\n","Epoch 4: val_loss improved from 0.00367 to 0.00268, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 45ms/step - loss: 0.0012 - val_loss: 0.0027\n","Epoch 5/100\n","113/113 [==============================] - ETA: 0s - loss: 0.0011\n","Epoch 5: val_loss did not improve from 0.00268\n","113/113 [==============================] - 6s 49ms/step - loss: 0.0011 - val_loss: 0.0035\n","Epoch 6/100\n","113/113 [==============================] - ETA: 0s - loss: 9.6492e-04\n","Epoch 6: val_loss did not improve from 0.00268\n","113/113 [==============================] - 6s 55ms/step - loss: 9.6492e-04 - val_loss: 0.0041\n","Epoch 7/100\n","112/113 [============================>.] - ETA: 0s - loss: 9.0750e-04\n","Epoch 7: val_loss did not improve from 0.00268\n","113/113 [==============================] - 5s 44ms/step - loss: 9.0213e-04 - val_loss: 0.0049\n","Epoch 8/100\n","112/113 [============================>.] - ETA: 0s - loss: 8.0412e-04\n","Epoch 8: val_loss did not improve from 0.00268\n","113/113 [==============================] - 5s 44ms/step - loss: 8.0169e-04 - val_loss: 0.0039\n","Epoch 9/100\n","112/113 [============================>.] - ETA: 0s - loss: 7.7491e-04\n","Epoch 9: val_loss improved from 0.00268 to 0.00165, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 45ms/step - loss: 7.7197e-04 - val_loss: 0.0016\n","Epoch 10/100\n","112/113 [============================>.] - ETA: 0s - loss: 7.7797e-04\n","Epoch 10: val_loss did not improve from 0.00165\n","113/113 [==============================] - 5s 45ms/step - loss: 7.7902e-04 - val_loss: 0.0024\n","Epoch 11/100\n","113/113 [==============================] - ETA: 0s - loss: 7.9420e-04\n","Epoch 11: val_loss did not improve from 0.00165\n","113/113 [==============================] - 5s 45ms/step - loss: 7.9420e-04 - val_loss: 0.0038\n","Epoch 12/100\n","113/113 [==============================] - ETA: 0s - loss: 7.2047e-04\n","Epoch 12: val_loss did not improve from 0.00165\n","113/113 [==============================] - 5s 45ms/step - loss: 7.2047e-04 - val_loss: 0.0023\n","Epoch 13/100\n","113/113 [==============================] - ETA: 0s - loss: 6.9833e-04\n","Epoch 13: val_loss improved from 0.00165 to 0.00131, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 44ms/step - loss: 6.9833e-04 - val_loss: 0.0013\n","Epoch 14/100\n","112/113 [============================>.] - ETA: 0s - loss: 6.4661e-04\n","Epoch 14: val_loss improved from 0.00131 to 0.00109, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 45ms/step - loss: 6.4556e-04 - val_loss: 0.0011\n","Epoch 15/100\n","112/113 [============================>.] - ETA: 0s - loss: 6.0892e-04\n","Epoch 15: val_loss improved from 0.00109 to 0.00099, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 45ms/step - loss: 6.0569e-04 - val_loss: 9.9146e-04\n","Epoch 16/100\n","113/113 [==============================] - ETA: 0s - loss: 6.7856e-04\n","Epoch 16: val_loss improved from 0.00099 to 0.00084, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 45ms/step - loss: 6.7856e-04 - val_loss: 8.4029e-04\n","Epoch 17/100\n","113/113 [==============================] - ETA: 0s - loss: 7.1524e-04\n","Epoch 17: val_loss did not improve from 0.00084\n","113/113 [==============================] - 5s 48ms/step - loss: 7.1524e-04 - val_loss: 8.4775e-04\n","Epoch 18/100\n","113/113 [==============================] - ETA: 0s - loss: 6.3343e-04\n","Epoch 18: val_loss did not improve from 0.00084\n","113/113 [==============================] - 6s 49ms/step - loss: 6.3343e-04 - val_loss: 0.0010\n","Epoch 19/100\n","113/113 [==============================] - ETA: 0s - loss: 6.0462e-04\n","Epoch 19: val_loss did not improve from 0.00084\n","113/113 [==============================] - 5s 47ms/step - loss: 6.0462e-04 - val_loss: 9.3502e-04\n","Epoch 20/100\n","112/113 [============================>.] - ETA: 0s - loss: 5.9003e-04\n","Epoch 20: val_loss improved from 0.00084 to 0.00076, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 48ms/step - loss: 5.8945e-04 - val_loss: 7.5741e-04\n","Epoch 21/100\n","113/113 [==============================] - ETA: 0s - loss: 5.8981e-04\n","Epoch 21: val_loss did not improve from 0.00076\n","113/113 [==============================] - 5s 47ms/step - loss: 5.8981e-04 - val_loss: 7.7090e-04\n","Epoch 22/100\n","113/113 [==============================] - ETA: 0s - loss: 5.4711e-04\n","Epoch 22: val_loss improved from 0.00076 to 0.00074, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 48ms/step - loss: 5.4711e-04 - val_loss: 7.4269e-04\n","Epoch 23/100\n","113/113 [==============================] - ETA: 0s - loss: 5.6198e-04\n","Epoch 23: val_loss did not improve from 0.00074\n","113/113 [==============================] - 7s 62ms/step - loss: 5.6198e-04 - val_loss: 9.1852e-04\n","Epoch 24/100\n","113/113 [==============================] - ETA: 0s - loss: 5.7225e-04\n","Epoch 24: val_loss did not improve from 0.00074\n","113/113 [==============================] - 5s 47ms/step - loss: 5.7225e-04 - val_loss: 7.9065e-04\n","Epoch 25/100\n","113/113 [==============================] - ETA: 0s - loss: 5.2062e-04\n","Epoch 25: val_loss did not improve from 0.00074\n","113/113 [==============================] - 5s 47ms/step - loss: 5.2062e-04 - val_loss: 7.6331e-04\n","Epoch 26/100\n","113/113 [==============================] - ETA: 0s - loss: 6.2837e-04\n","Epoch 26: val_loss did not improve from 0.00074\n","113/113 [==============================] - 6s 49ms/step - loss: 6.2837e-04 - val_loss: 7.5975e-04\n","Epoch 27/100\n","112/113 [============================>.] - ETA: 0s - loss: 6.0702e-04\n","Epoch 27: val_loss did not improve from 0.00074\n","113/113 [==============================] - 6s 49ms/step - loss: 6.0389e-04 - val_loss: 8.2815e-04\n","Epoch 28/100\n","113/113 [==============================] - ETA: 0s - loss: 5.4938e-04\n","Epoch 28: val_loss did not improve from 0.00074\n","113/113 [==============================] - 5s 48ms/step - loss: 5.4938e-04 - val_loss: 8.4752e-04\n","Epoch 29/100\n","113/113 [==============================] - ETA: 0s - loss: 5.6842e-04\n","Epoch 29: val_loss did not improve from 0.00074\n","113/113 [==============================] - 5s 47ms/step - loss: 5.6842e-04 - val_loss: 0.0013\n","Epoch 30/100\n","112/113 [============================>.] - ETA: 0s - loss: 6.3432e-04\n","Epoch 30: val_loss improved from 0.00074 to 0.00073, saving model to model/tmp_checkpoint.h5\n","113/113 [==============================] - 5s 47ms/step - loss: 6.3292e-04 - val_loss: 7.2785e-04\n","Epoch 31/100\n","113/113 [==============================] - ETA: 0s - loss: 4.9993e-04\n","Epoch 31: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 48ms/step - loss: 4.9993e-04 - val_loss: 8.9012e-04\n","Epoch 32/100\n","113/113 [==============================] - ETA: 0s - loss: 4.8885e-04\n","Epoch 32: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 48ms/step - loss: 4.8885e-04 - val_loss: 0.0012\n","Epoch 33/100\n","112/113 [============================>.] - ETA: 0s - loss: 5.4841e-04\n","Epoch 33: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 48ms/step - loss: 5.5114e-04 - val_loss: 7.9049e-04\n","Epoch 34/100\n","113/113 [==============================] - ETA: 0s - loss: 5.3649e-04\n","Epoch 34: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 48ms/step - loss: 5.3649e-04 - val_loss: 9.4865e-04\n","Epoch 35/100\n","112/113 [============================>.] - ETA: 0s - loss: 4.9231e-04\n","Epoch 35: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 48ms/step - loss: 4.9338e-04 - val_loss: 0.0010\n","Epoch 36/100\n","112/113 [============================>.] - ETA: 0s - loss: 5.1969e-04\n","Epoch 36: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 47ms/step - loss: 5.1845e-04 - val_loss: 8.2620e-04\n","Epoch 37/100\n","112/113 [============================>.] - ETA: 0s - loss: 6.5416e-04\n","Epoch 37: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 47ms/step - loss: 6.5516e-04 - val_loss: 9.1890e-04\n","Epoch 38/100\n","112/113 [============================>.] - ETA: 0s - loss: 5.1810e-04\n","Epoch 38: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 47ms/step - loss: 5.1597e-04 - val_loss: 7.3555e-04\n","Epoch 39/100\n","113/113 [==============================] - ETA: 0s - loss: 4.9270e-04\n","Epoch 39: val_loss did not improve from 0.00073\n","113/113 [==============================] - 5s 47ms/step - loss: 4.9270e-04 - val_loss: 0.0016\n","Epoch 40/100\n","112/113 [============================>.] - ETA: 0s - loss: 5.1453e-04\n","Epoch 40: val_loss did not improve from 0.00073\n","113/113 [==============================] - 7s 63ms/step - loss: 5.1271e-04 - val_loss: 0.0016\n","4000길이의 데이터 적용 완료\n"," 길이: 4000, RMSE:1233.0965835590926\n","[2834.579947819444, 1356.3687319050114, 1277.7690059375616, 1233.0965835590926]\n"]}],"source":["!pip install ta\n","#데이터셋을 만들어 주는 함수\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","from keras.layers import LSTM,Dropout,GRU\n","import os\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/HEM/data/_금융_KB금융.csv\")\n","df_columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n","df.columns = df_columns\n","df = df.sort_values('Date')\n","df['Date']= df['Date'].astype('str')\n","from datetime import datetime\n","df['Date'] = pd.to_datetime(df['Date'])\n","df.set_index('Date',inplace=True)\n","\n","ma = [5,20,60,120]\n","for days in ma:\n","    df['ma_'+str(days)] = df['Close'].rolling(window = days).mean()\n","    df['vma_'+str(days)] = df['Volume'].rolling(window = days).mean()\n","\n","df.dropna(inplace=True)\n","\n","\n","import ta\n","\n","H, L, C, V = df['High'], df['Low'], df['Close'], df['Volume']\n","\n","# df['bol_high'] = ta.volatility.bollinger_hband(C)\n","# df['bol_low']  = ta.volatility.bollinger_lband(C)\n","df['MFI'] = ta.volume.money_flow_index(\n","    high=H, low=L, close=C, volume=V, fillna=True)\n","\n","df['ADI'] = ta.volume.acc_dist_index(\n","    high=H, low=L, close=C, volume=V, fillna=True)\n","\n","df['OBV'] = ta.volume.on_balance_volume(close=C, volume=V, fillna=True)\n","df['CMF'] = ta.volume.chaikin_money_flow(\n","    high=H, low=L, close=C, volume=V, fillna=True)\n","\n","df['FI'] = ta.volume.force_index(close=C, volume=V, fillna=True)\n","df['EOM, EMV'] = ta.volume.ease_of_movement(\n","    high=H, low=L, volume=V, fillna=True)\n","\n","df['VPT'] = ta.volume.volume_price_trend(close=C, volume=V, fillna=True)\n","df['NVI'] = ta.volume.negative_volume_index(close=C, volume=V, fillna=True)\n","df['VMAP'] = ta.volume.volume_weighted_average_price(\n","    high=H, low=L, close=C, volume=V, fillna=True)\n","\n","# Volatility\n","df['ATR'] = ta.volatility.average_true_range(\n","    high=H, low=L, close=C, fillna=True)\n","df['BHB'] = ta.volatility.bollinger_hband(close=C, fillna=True)\n","df['BLB'] = ta.volatility.bollinger_lband(close=C, fillna=True)\n","df['KCH'] = ta.volatility.keltner_channel_hband(\n","    high=H, low=L, close=C, fillna=True)\n","df['KCL'] = ta.volatility.keltner_channel_lband(\n","    high=H, low=L, close=C, fillna=True)\n","df['KCM'] = ta.volatility.keltner_channel_mband(\n","    high=H, low=L, close=C, fillna=True)\n","df['DCH'] = ta.volatility.donchian_channel_hband(\n","    high=H, low=L, close=C, fillna=True)\n","df['DCL'] = ta.volatility.donchian_channel_lband(\n","    high=H, low=L, close=C, fillna=True)\n","df['DCM'] = ta.volatility.donchian_channel_mband(\n","    high=H, low=L, close=C, fillna=True)\n","df['UI'] = ta.volatility.ulcer_index(close=C, fillna=True)\n","# Trend\n","df['SMA'] = ta.trend.sma_indicator(close=C, fillna=True)\n","df['EMA'] = ta.trend.ema_indicator(close=C, fillna=True)\n","df['WMA'] = ta.trend.wma_indicator(close=C, fillna=True)\n","df['MACD'] = ta.trend.macd(close=C, fillna=True)\n","df['ADX'] = ta.trend.adx(high=H, low=L, close=C, fillna=True)\n","df['-VI'] = ta.trend.vortex_indicator_neg(\n","    high=H, low=L, close=C, fillna=True)\n","df['+VI'] = ta.trend.vortex_indicator_pos(\n","    high=H, low=L, close=C, fillna=True)\n","df['TRIX'] = ta.trend.trix(close=C, fillna=True)\n","df['MI'] = ta.trend.mass_index(high=H, low=L, fillna=True)\n","df['CCI'] = ta.trend.cci(high=H, low=L, close=C, fillna=True)\n","df['DPO'] = ta.trend.dpo(close=C, fillna=True)\n","df['KST'] = ta.trend.kst(close=C, fillna=True)\n","df['Ichimoku'] = ta.trend.ichimoku_a(high=H, low=L, fillna=True)\n","df['Parabolic SAR'] = ta.trend.psar_down(\n","    high=H, low=L, close=C, fillna=True)\n","df['STC'] = ta.trend.stc(close=C, fillna=True)\n","# Momentum\n","df['RSI'] = ta.momentum.rsi(close=C, fillna=True)\n","df['SRSI'] = ta.momentum.stochrsi(close=C, fillna=True)\n","df['TSI'] = ta.momentum.tsi(close=C, fillna=True)\n","df['UO'] = ta.momentum.ultimate_oscillator(\n","    high=H, low=L, close=C, fillna=True)\n","df['SR'] = ta.momentum.stoch(close=C, high=H, low=L, fillna=True)\n","df['WR'] = ta.momentum.williams_r(high=H, low=L, close=C, fillna=True)\n","df['AO'] = ta.momentum.awesome_oscillator(high=H, low=L, fillna=True)\n","df['KAMA'] = ta.momentum.kama(close=C, fillna=True)\n","df['ROC'] = ta.momentum.roc(close=C, fillna=True)\n","df['PPO'] = ta.momentum.ppo(close=C, fillna=True)\n","df['PVO'] = ta.momentum.pvo(volume=V, fillna=True)\n","\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# 피처값 스케일링\n","scaler = MinMaxScaler()\n","\n","scaled_df = scaler.fit_transform(df.drop(['Close'], axis=1))\n","scaled_df = pd.DataFrame(scaled_df, columns = df.drop(['Close'], axis=1).columns)\n","\n","scaler1 = MinMaxScaler()\n","\n","temp = scaler1.fit_transform(df['Close'].values.reshape(-1,1))\n","\n","scaled_df.insert(3, 'Close',temp)\n","scaled_df\n","\n","df = scaled_df\n","\n","\n","\n","import numpy as np\n","\n","def make_dataset(feature, label, window_size = 20):\n","  \n","  feature_list = []\n","  label_list = []\n","  \n","  for i in range(len(feature) - window_size) :\n","    feature_list.append(feature.iloc[i:i+window_size])\n","    label_list.append(label.iloc[i+window_size])\n","  \n","  return np.array(feature_list), np.array(label_list)\n","\n","WINDOW_SIZE=20\n","\n","result = []\n","predict = []\n","\n","\n","####최근 20개의 데이터만\n","pred_feature = df[-WINDOW_SIZE :]\n","pred_feature = pred_feature.to_numpy()\n","\n","pred_feature = pred_feature.reshape((1,20,-1))\n","# pred_feature.shape\n","\n","import random as rn\n","import tensorflow as tf\n","\n","\n","for i in range(1, len(df)//1000+2):\n","\n","        # 데이터 불러오기\n","        df_copy = df\n","     \n","        # 원하는 크기로 데이터 자르기\n","        df_copy = df_copy[-i*1000:]\n","        # 피처값, 타켓 스케일링\n","        \n","        TEST_SIZE = int(len(df_copy) * 0.7)\n","        \n","        train = df_copy[:TEST_SIZE]\n","        test = df_copy[TEST_SIZE:]\n","\n","##200일의 데이터를 얼마나 잘 예측하느냐\n","        \n","        # feature_cols = df.drop('Close', axis =1).columns\n","        feature_cols = df.columns\n","        label_cols = ['Close']\n","\n","        train_feature = train[feature_cols]\n","        train_label = train[label_cols]\n","\n","        train_feature, train_label = make_dataset(train_feature, train_label,20)\n","\n","        from sklearn.model_selection import train_test_split\n","        x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2, shuffle = False)\n","        \n","        \n","        test_feature = test[feature_cols]\n","        test_label = test[label_cols]\n","        test_feature , test_label = make_dataset(test_feature, test_label,20)\n","        \n","        \n","        from keras.layers.normalization import batch_normalization\n","\n","        model = Sequential()\n","        model.add(GRU(16, \n","                      input_shape=(train_feature.shape[1], train_feature.shape[2]), \n","                      return_sequences = False, \n","                      activation='relu'))\n","        model.add(Dense(1))\n","      \n","        \n","        model.compile(loss='mean_squared_error', optimizer='adam')\n","\n","        early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","\n","        import os\n","        from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","        model_path = 'model'\n","        filename = os.path.join(model_path, 'tmp_checkpoint.h5')\n","        checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","\n","        history = model.fit(x_train, y_train, \n","                                            epochs=100, \n","                                            batch_size=16,\n","                                            validation_data=(x_valid, y_valid), \n","                                            callbacks=[early_stop, checkpoint])\n","\n","\n","        pred = model.predict(test_feature)\n","        # rescaleing 작업\n","        rescaled_y_true = scaler1.inverse_transform(np.array(test_label).reshape(-1, 1))\n","        rescaled_pred = scaler1.inverse_transform(np.array(pred).reshape(-1,1))\n","        \n","        \n","        # 평가지표(RMSE) 계산\n","        RMSE = np.sqrt(mean_squared_error(rescaled_y_true, rescaled_pred))\n","        result.append(RMSE)\n","        print(f\"{i * 1000}길이의 데이터 적용 완료\\n 길이: {i * 1000}, RMSE:{RMSE}\")\n","        print(result)\n","        \n","        \n","        model.load_weights(filename)\n","\n","        new_pred = model.predict(pred_feature)\n","        rescaled_newpred = scaler1.inverse_transform(np.array(new_pred).reshape(-1,1))\n","        predict.append(rescaled_newpred)\n","\n"]},{"cell_type":"code","source":["predict"],"metadata":{"id":"hEfbu0U3pOkB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657975983058,"user_tz":-540,"elapsed":30,"user":{"displayName":"박민규","userId":"00586156377257418934"}},"outputId":"cb5ad463-d181-4d78-91eb-9b7efbbdf920"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[58046.01]], dtype=float32),\n"," array([[60422.92]], dtype=float32),\n"," array([[60284.645]], dtype=float32),\n"," array([[59532.793]], dtype=float32)]"]},"metadata":{},"execution_count":3}]}]}
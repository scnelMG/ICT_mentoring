{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sQZP-mN8EEi",
    "outputId": "9affed2f-3086-40f3-bd99-38f67be497fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ta in c:\\users\\gram\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\gram\\anaconda3\\lib\\site-packages (from ta) (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gram\\anaconda3\\lib\\site-packages (from ta) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gram\\anaconda3\\lib\\site-packages (from pandas->ta) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gram\\anaconda3\\lib\\site-packages (from pandas->ta) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gram\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->ta) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gram\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "C:\\Users\\gram\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 1: val_loss improved from inf to 0.00111, saving model to model\\tmp_checkpoint.h5\n",
      "34/34 [==============================] - 12s 126ms/step - loss: 0.0141 - val_loss: 0.0011\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0010\n",
      "Epoch 2: val_loss did not improve from 0.00111\n",
      "34/34 [==============================] - 2s 65ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 5.5704e-04\n",
      "Epoch 3: val_loss improved from 0.00111 to 0.00089, saving model to model\\tmp_checkpoint.h5\n",
      "34/34 [==============================] - 2s 70ms/step - loss: 5.5704e-04 - val_loss: 8.9207e-04\n",
      "Epoch 4/100\n",
      "33/34 [============================>.] - ETA: 0s - loss: 4.9190e-04\n",
      "Epoch 4: val_loss improved from 0.00089 to 0.00066, saving model to model\\tmp_checkpoint.h5\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 5.0004e-04 - val_loss: 6.5653e-04\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 5.5315e-04\n",
      "Epoch 5: val_loss improved from 0.00066 to 0.00062, saving model to model\\tmp_checkpoint.h5\n",
      "34/34 [==============================] - 2s 65ms/step - loss: 5.5315e-04 - val_loss: 6.1629e-04\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.5361e-04\n",
      "Epoch 6: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 55ms/step - loss: 3.5361e-04 - val_loss: 8.9336e-04\n",
      "Epoch 7/100\n",
      "33/34 [============================>.] - ETA: 0s - loss: 3.7197e-04\n",
      "Epoch 7: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 62ms/step - loss: 3.7061e-04 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "33/34 [============================>.] - ETA: 0s - loss: 3.2769e-04\n",
      "Epoch 8: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 3.2365e-04 - val_loss: 9.7116e-04\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.1716e-04\n",
      "Epoch 9: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 59ms/step - loss: 3.1716e-04 - val_loss: 0.0012\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.9899e-04\n",
      "Epoch 10: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 50ms/step - loss: 2.9899e-04 - val_loss: 0.0015\n",
      "Epoch 11/100\n",
      "33/34 [============================>.] - ETA: 0s - loss: 2.9259e-04\n",
      "Epoch 11: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 48ms/step - loss: 2.8875e-04 - val_loss: 7.6760e-04\n",
      "Epoch 12/100\n",
      "33/34 [============================>.] - ETA: 0s - loss: 2.9763e-04\n",
      "Epoch 12: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 45ms/step - loss: 2.9916e-04 - val_loss: 0.0015\n",
      "Epoch 13/100\n",
      "33/34 [============================>.] - ETA: 0s - loss: 3.1761e-04\n",
      "Epoch 13: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 2s 54ms/step - loss: 3.1581e-04 - val_loss: 6.9270e-04\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.9134e-04\n",
      "Epoch 14: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.9134e-04 - val_loss: 0.0011\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.7102e-04\n",
      "Epoch 15: val_loss did not improve from 0.00062\n",
      "34/34 [==============================] - 1s 39ms/step - loss: 2.7102e-04 - val_loss: 7.0743e-04\n",
      "1000길이의 데이터 적용 완료\n",
      " 길이: 1000, RMSE:30034.13572534102\n",
      "[30034.13572534102]\n",
      "Epoch 1/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 1: val_loss improved from inf to 0.00785, saving model to model\\tmp_checkpoint.h5\n",
      "43/43 [==============================] - 8s 74ms/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 4.7728e-04\n",
      "Epoch 2: val_loss improved from 0.00785 to 0.00638, saving model to model\\tmp_checkpoint.h5\n",
      "43/43 [==============================] - 2s 51ms/step - loss: 4.7728e-04 - val_loss: 0.0064\n",
      "Epoch 3/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 3.7963e-04\n",
      "Epoch 3: val_loss improved from 0.00638 to 0.00637, saving model to model\\tmp_checkpoint.h5\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 3.8094e-04 - val_loss: 0.0064\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.2405e-04\n",
      "Epoch 4: val_loss did not improve from 0.00637\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 3.2405e-04 - val_loss: 0.0069\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.7748e-04\n",
      "Epoch 5: val_loss improved from 0.00637 to 0.00615, saving model to model\\tmp_checkpoint.h5\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 2.7748e-04 - val_loss: 0.0062\n",
      "Epoch 6/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.5787e-04\n",
      "Epoch 6: val_loss improved from 0.00615 to 0.00471, saving model to model\\tmp_checkpoint.h5\n",
      "43/43 [==============================] - 2s 51ms/step - loss: 2.5690e-04 - val_loss: 0.0047\n",
      "Epoch 7/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 3.4688e-04\n",
      "Epoch 7: val_loss did not improve from 0.00471\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 3.4974e-04 - val_loss: 0.0090\n",
      "Epoch 8/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.5624e-04\n",
      "Epoch 8: val_loss did not improve from 0.00471\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 2.5416e-04 - val_loss: 0.0048\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.5588e-04\n",
      "Epoch 9: val_loss did not improve from 0.00471\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 2.5588e-04 - val_loss: 0.0054\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.2955e-04\n",
      "Epoch 10: val_loss did not improve from 0.00471\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 2.2955e-04 - val_loss: 0.0054\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 3.0374e-04\n",
      "Epoch 11: val_loss did not improve from 0.00471\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 3.0374e-04 - val_loss: 0.0059\n",
      "Epoch 12/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.1318e-04\n",
      "Epoch 12: val_loss improved from 0.00471 to 0.00286, saving model to model\\tmp_checkpoint.h5\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 2.1390e-04 - val_loss: 0.0029\n",
      "Epoch 13/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 3.0446e-04\n",
      "Epoch 13: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 3.0414e-04 - val_loss: 0.0049\n",
      "Epoch 14/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.6087e-04\n",
      "Epoch 14: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 41ms/step - loss: 2.5910e-04 - val_loss: 0.0038\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.9571e-04\n",
      "Epoch 15: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 2.9571e-04 - val_loss: 0.0060\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.4666e-04\n",
      "Epoch 16: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 2.4666e-04 - val_loss: 0.0032\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.4209e-04\n",
      "Epoch 17: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 2.4209e-04 - val_loss: 0.0061\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.9545e-04\n",
      "Epoch 18: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 52ms/step - loss: 1.9545e-04 - val_loss: 0.0063\n",
      "Epoch 19/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.4068e-04\n",
      "Epoch 19: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 2.4084e-04 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.2462e-04\n",
      "Epoch 20: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 2.2283e-04 - val_loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.3954e-04\n",
      "Epoch 21: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 42ms/step - loss: 2.3954e-04 - val_loss: 0.0062\n",
      "Epoch 22/100\n",
      "42/43 [============================>.] - ETA: 0s - loss: 2.2215e-04\n",
      "Epoch 22: val_loss did not improve from 0.00286\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 2.2374e-04 - val_loss: 0.0038\n",
      "2000길이의 데이터 적용 완료\n",
      " 길이: 2000, RMSE:60588.591945447115\n",
      "[30034.13572534102, 60588.591945447115]\n"
     ]
    }
   ],
   "source": [
    "!pip install ta\n",
    "#데이터셋을 만들어 주는 함수\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM,Dropout,GRU\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"./[건강관리]삼성바이오로직스.csv\")\n",
    "df_columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "df.columns = df_columns\n",
    "df = df.sort_values('Date')\n",
    "df['Date']= df['Date'].astype('str')\n",
    "from datetime import datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date',inplace=True)\n",
    "\n",
    "ma = [5,20,60,120]\n",
    "for days in ma:\n",
    "    df['ma_'+str(days)] = df['Close'].rolling(window = days).mean()\n",
    "    df['vma_'+str(days)] = df['Volume'].rolling(window = days).mean()\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "import ta\n",
    "\n",
    "H, L, C, V = df['High'], df['Low'], df['Close'], df['Volume']\n",
    "\n",
    "# df['bol_high'] = ta.volatility.bollinger_hband(C)\n",
    "# df['bol_low']  = ta.volatility.bollinger_lband(C)\n",
    "df['MFI'] = ta.volume.money_flow_index(\n",
    "    high=H, low=L, close=C, volume=V, fillna=True)\n",
    "\n",
    "df['ADI'] = ta.volume.acc_dist_index(\n",
    "    high=H, low=L, close=C, volume=V, fillna=True)\n",
    "\n",
    "df['OBV'] = ta.volume.on_balance_volume(close=C, volume=V, fillna=True)\n",
    "df['CMF'] = ta.volume.chaikin_money_flow(\n",
    "    high=H, low=L, close=C, volume=V, fillna=True)\n",
    "\n",
    "df['FI'] = ta.volume.force_index(close=C, volume=V, fillna=True)\n",
    "df['EOM, EMV'] = ta.volume.ease_of_movement(\n",
    "    high=H, low=L, volume=V, fillna=True)\n",
    "\n",
    "df['VPT'] = ta.volume.volume_price_trend(close=C, volume=V, fillna=True)\n",
    "df['NVI'] = ta.volume.negative_volume_index(close=C, volume=V, fillna=True)\n",
    "df['VMAP'] = ta.volume.volume_weighted_average_price(\n",
    "    high=H, low=L, close=C, volume=V, fillna=True)\n",
    "\n",
    "# Volatility\n",
    "df['ATR'] = ta.volatility.average_true_range(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['BHB'] = ta.volatility.bollinger_hband(close=C, fillna=True)\n",
    "df['BLB'] = ta.volatility.bollinger_lband(close=C, fillna=True)\n",
    "df['KCH'] = ta.volatility.keltner_channel_hband(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['KCL'] = ta.volatility.keltner_channel_lband(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['KCM'] = ta.volatility.keltner_channel_mband(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['DCH'] = ta.volatility.donchian_channel_hband(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['DCL'] = ta.volatility.donchian_channel_lband(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['DCM'] = ta.volatility.donchian_channel_mband(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['UI'] = ta.volatility.ulcer_index(close=C, fillna=True)\n",
    "# Trend\n",
    "df['SMA'] = ta.trend.sma_indicator(close=C, fillna=True)\n",
    "df['EMA'] = ta.trend.ema_indicator(close=C, fillna=True)\n",
    "df['WMA'] = ta.trend.wma_indicator(close=C, fillna=True)\n",
    "df['MACD'] = ta.trend.macd(close=C, fillna=True)\n",
    "df['ADX'] = ta.trend.adx(high=H, low=L, close=C, fillna=True)\n",
    "df['-VI'] = ta.trend.vortex_indicator_neg(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['+VI'] = ta.trend.vortex_indicator_pos(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['TRIX'] = ta.trend.trix(close=C, fillna=True)\n",
    "df['MI'] = ta.trend.mass_index(high=H, low=L, fillna=True)\n",
    "df['CCI'] = ta.trend.cci(high=H, low=L, close=C, fillna=True)\n",
    "df['DPO'] = ta.trend.dpo(close=C, fillna=True)\n",
    "df['KST'] = ta.trend.kst(close=C, fillna=True)\n",
    "df['Ichimoku'] = ta.trend.ichimoku_a(high=H, low=L, fillna=True)\n",
    "df['Parabolic SAR'] = ta.trend.psar_down(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['STC'] = ta.trend.stc(close=C, fillna=True)\n",
    "# Momentum\n",
    "df['RSI'] = ta.momentum.rsi(close=C, fillna=True)\n",
    "df['SRSI'] = ta.momentum.stochrsi(close=C, fillna=True)\n",
    "df['TSI'] = ta.momentum.tsi(close=C, fillna=True)\n",
    "df['UO'] = ta.momentum.ultimate_oscillator(\n",
    "    high=H, low=L, close=C, fillna=True)\n",
    "df['SR'] = ta.momentum.stoch(close=C, high=H, low=L, fillna=True)\n",
    "df['WR'] = ta.momentum.williams_r(high=H, low=L, close=C, fillna=True)\n",
    "df['AO'] = ta.momentum.awesome_oscillator(high=H, low=L, fillna=True)\n",
    "df['KAMA'] = ta.momentum.kama(close=C, fillna=True)\n",
    "df['ROC'] = ta.momentum.roc(close=C, fillna=True)\n",
    "df['PPO'] = ta.momentum.ppo(close=C, fillna=True)\n",
    "df['PVO'] = ta.momentum.pvo(volume=V, fillna=True)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 피처값 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_df = scaler.fit_transform(df.drop(['Close'], axis=1))\n",
    "scaled_df = pd.DataFrame(scaled_df, columns = df.drop(['Close'], axis=1).columns)\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "\n",
    "temp = scaler1.fit_transform(df['Close'].values.reshape(-1,1))\n",
    "\n",
    "scaled_df.insert(3, 'Close',temp)\n",
    "scaled_df\n",
    "\n",
    "df = scaled_df\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def make_dataset(feature, label, window_size = 20):\n",
    "  \n",
    "  feature_list = []\n",
    "  label_list = []\n",
    "  \n",
    "  for i in range(len(feature) - window_size) :\n",
    "    feature_list.append(feature.iloc[i:i+window_size])\n",
    "    label_list.append(label.iloc[i+window_size])\n",
    "  \n",
    "  return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "WINDOW_SIZE=20\n",
    "\n",
    "result = []\n",
    "predict = []\n",
    "\n",
    "\n",
    "####최근 20개의 데이터만\n",
    "pred_feature = df[-WINDOW_SIZE :]\n",
    "pred_feature = pred_feature.to_numpy()\n",
    "\n",
    "pred_feature = pred_feature.reshape((1,20,-1))\n",
    "# pred_feature.shape\n",
    "\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "for i in range(1, len(df)//1000+2):\n",
    "\n",
    "        # 데이터 불러오기\n",
    "        df_copy = df\n",
    "     \n",
    "        # 원하는 크기로 데이터 자르기\n",
    "        df_copy = df_copy[-i*1000:]\n",
    "        # 피처값, 타켓 스케일링\n",
    "        \n",
    "        TEST_SIZE = int(len(df_copy) * 0.7)\n",
    "        \n",
    "        train = df_copy[:TEST_SIZE]\n",
    "        test = df_copy[TEST_SIZE:]\n",
    "\n",
    "##200일의 데이터를 얼마나 잘 예측하느냐\n",
    "        \n",
    "        # feature_cols = df.drop('Close', axis =1).columns\n",
    "        feature_cols = df.columns\n",
    "        label_cols = ['Close']\n",
    "\n",
    "        train_feature = train[feature_cols]\n",
    "        train_label = train[label_cols]\n",
    "\n",
    "        train_feature, train_label = make_dataset(train_feature, train_label,20)\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2, shuffle = False)\n",
    "        \n",
    "        \n",
    "        test_feature = test[feature_cols]\n",
    "        test_label = test[label_cols]\n",
    "        test_feature , test_label = make_dataset(test_feature, test_label,20)\n",
    "        \n",
    "        \n",
    "        from keras.layers.normalization import batch_normalization\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(GRU(128, \n",
    "                      input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "                      return_sequences = True,\n",
    "                      activation='relu'))\n",
    "        model.add(GRU(128, return_sequences=False, stateful=False))\n",
    "        model.add(Dense(1))\n",
    "      \n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "        import os\n",
    "        from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "        model_path = 'model'\n",
    "        filename = os.path.join(model_path, 'tmp_checkpoint.h5')\n",
    "        checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "        history = model.fit(x_train, y_train, \n",
    "                                            epochs=100, \n",
    "                                            batch_size=16,\n",
    "                                            validation_data=(x_valid, y_valid), \n",
    "                                            callbacks=[early_stop, checkpoint])\n",
    "\n",
    "\n",
    "        pred = model.predict(test_feature)\n",
    "        # rescaleing 작업\n",
    "        rescaled_y_true = scaler1.inverse_transform(np.array(test_label).reshape(-1, 1))\n",
    "        rescaled_pred = scaler1.inverse_transform(np.array(pred).reshape(-1,1))\n",
    "        \n",
    "        \n",
    "        # 평가지표(RMSE) 계산\n",
    "        RMSE = np.sqrt(mean_squared_error(rescaled_y_true, rescaled_pred))\n",
    "        result.append(RMSE)\n",
    "        print(f\"{i * 1000}길이의 데이터 적용 완료\\n 길이: {i * 1000}, RMSE:{RMSE}\")\n",
    "        print(result)\n",
    "        \n",
    "        \n",
    "        model.load_weights(filename)\n",
    "\n",
    "        new_pred = model.predict(pred_feature)\n",
    "        rescaled_newpred = scaler1.inverse_transform(np.array(new_pred).reshape(-1,1))\n",
    "        predict.append(rescaled_newpred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEfbu0U3pOkB",
    "outputId": "95029b61-2705-4c95-9e95-5e93797a0d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[830129.7]], dtype=float32), array([[801139.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gru_이중층유닛16_dropout 사용x_batch_norm 사용x.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
